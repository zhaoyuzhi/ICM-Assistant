# -*- coding: utf-8 -*-
import os
import openai
import time
import argparse

# read a txt expect EOF
def text_readlines(filename, mode = 'r'):
    # try to read a txt file and return a list.Return [] if there was a mistake.
    try:
        # Use the following command if there is Chinese characters are read
        file = open(filename, mode, encoding = 'utf-8')
        # file = open(filename, mode)
    except IOError:
        error = []
        return error
    content = file.readlines()
    # This for loop deletes the EOF (like \n)
    for i in range(len(content)):
        content[i] = content[i][:len(content[i]) - 1]
    file.close()
    return content

# save a list to a txt
def text_save(content, filename, mode = 'a'):
    # try to save a list variable in txt file.
    # Use the following command if Chinese characters are written (i.e., text in the file will be encoded in utf-8)
    file = open(filename, mode, encoding = 'utf-8')
    # file = open(filename, mode)
    for i in range(len(content)):
        file.write(str(content[i]) + '\n')
    file.close()

# multi-layer folder creation
def check_path(path):
    if not os.path.exists(path):
        os.makedirs(path)

# call LLM
def llm_client(api_key, llm_model, system_message, user_content):
    request_start = time.time()

    # load api key
    openai.api_key = api_key
    response = openai.ChatCompletion.create(
        model = llm_model,
        messages = [
            {"role": "system",
             "content": system_message},
            {"role": "user",
             "content": user_content},
        ],
        temperature = 0.2,
        top_p = 1.0,
        frequency_penalty = 0.0,
        presence_penalty = 0.0
    )

    request_duration = time.time() - request_start

    print(f"Successful LLM query. It took {request_duration:.2f}s")

    return response.choices[0]["message"]["content"]


if __name__ == "__main__":

    # using OpenAI's ChatGPT to label data
    parser = argparse.ArgumentParser()
    parser.add_argument('--api_key', type = str, default = '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', help = 'api key of OpenAI')
    parser.add_argument('--model', type = str, default = 'gpt-4o', help = 'model of OpenAI, e.g., gpt-3.5-turbo-1106, gpt-4-turbo-preview')
    parser.add_argument('--human_txt_path', type = str, default = './gt_description.txt', help = 'File path')
    parser.add_argument('--algo_txt_path', type = str, default = './llava-v1.5-7b-after-baseline.txt', help = 'File path')
    parser.add_argument('--save_path', type = str, default = './llava-v1.5-7b-after-baseline/', help = 'File save path')
    opt = parser.parse_args()
    print(opt)

    # define source and saving paths
    human_txt_list = text_readlines(opt.human_txt_path)
    algo_txt_list = text_readlines(opt.algo_txt_path)
    text_list_half_length = len(human_txt_list) // 2
    save_path = os.path.join(opt.save_path, opt.model, opt.algo_txt_path.split('/')[-1].split('.txt')[0])
    check_path(save_path)
    
    # define input
    system_message = 'You are a helpful and precise assistant for checking the quality of the answer.'
    instruction1 = 'Task: You will receive two descriptions, both explaining why the same image is sexy or not sexy. One of the descriptions is written by a real person, indicated by the title "Real person\'s description"; The other description is generated by an algorithm, indicated by the title "Algorithm\'s description". Please read the two descriptions carefully and evaluate the quality of "Algorithm\'s description" based on the content of "Real person\'s description". Note that: 1. the "Real person\'s description" is accurate; 2. do not only compare the lengths of two descriptions. The response is in the format of a table, where there are two columns: "Criteria" and "Score". Under column "Criteria", there are four rows: "Accuracy", "Preciseness", "Comprehensiveness", and "Fluency". You need to fill in their scores under the column "Score", which are in 0-100. Below are definitions:\n\n'
    instruction2 = '"Accuracy" score: This measures how closely the "Algorithm\'s description" matches the "Real person\'s description" in explaining the image.\n\n"Preciseness" score: It measures the inclusion of details in the "Algorithm\'s description" that are not mentioned or implied in "Real person\'s description". If "Algorithm\'s description" includes fewer explanations that are not spelled out in "Real person\'s description", the "Preciseness" score is higher.\n\n"comprehensiveness" score: This measures whether the "Algorithm\'s description" covers all aspects mentioned in "Real person\'s description".\n\n"Fluency" score: It measures how fluent of the presentation of the "Algorithm\'s description".\n\n'
    user_content_title1 = 'Real person\'s description: '
    user_content_title2 = '\n\nAlgorithm\'s description: '
    
    for i in range(0, text_list_half_length):
        
        # extract the image_name and user_content
        image_name = human_txt_list[i*2].split('/')[-1]
        human_content = human_txt_list[i*2+1]
        algo_content = algo_txt_list[i*2+1]
        print(i, text_list_half_length, image_name)

        # define the specific format of input prompt
        input_content = instruction1 + instruction2 + user_content_title1 + human_content + user_content_title2 + algo_content
        
        # forward LLM
        text = llm_client(opt.api_key, opt.model, system_message, input_content)

        # save the generated contents to a file
        save_list = []
        save_list.append(image_name + '\n')
        save_list.append('Human content:\n' + human_content + '\n')
        save_list.append('Algorithm content:\n' + algo_content + '\n')
        save_list.append('ChatGPT evaluation:\n' + text)
        text_save(save_list, os.path.join(save_path, '%s.txt' % image_name.split('.')[0]), mode = 'a')
        
